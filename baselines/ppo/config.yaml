defaults:
  exp_name: ppo_baseline
  seed: 0
  torch_deterministic: true
  cuda: true
  track: true
  wandb_project: "baseline-715"
  wandb_entity: null
  capture_video: false

  task: gymnasium_TigerDoorKey-v0
  total_timesteps: 500000
  num_envs: 8
  use_wandb: true

  # PPO Hyperparameters (Stable Baselines 3 defaults with some stability improvements)
  ppo:
    learning_rate: 3e-4      # Default SB3 learning rate
    n_steps: 2048           # Number of steps to run for each environment per update
    batch_size: 64          # Minibatch size
    n_epochs: 10            # Number of epoch when optimizing the surrogate loss
    gamma: 0.99             # Discount factor
    gae_lambda: 0.95        # Factor for trade-off of bias vs variance for GAE
    clip_range: 0.2         # Clipping parameter for PPO
    clip_range_vf: null     # Clipping parameter for value function (null = no clipping)
    ent_coef: 0.0           # Entropy coefficient for the loss calculation
    vf_coef: 0.5            # Value function coefficient for the loss calculation
    max_grad_norm: 0.5      # Maximum value for the gradient clipping

  # Teacher and student observation keys
  keys: {mlp_keys: '.*', cnn_keys: '.*'}
  num_eval_configs: 8
  eval_keys:
    env1:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env2:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env3:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env4:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env5:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env6:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env7:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env8:
      mlp_keys: '.*'
      cnn_keys: '.*'

  save_model: false
  log_keys_video: [image]

  # Environment settings
  env:
    atari: {size: [64, 64], repeat: 4, sticky: True, gray: False, actions: all, lives: unused, noops: 0, resize: opencv}
    dmlab: {size: [64, 64], repeat: 4, episodic: True}
    minecraft: {size: [64, 64], break_speed: 100.0}
    dmc: {size: [64, 64], repeat: 2, camera: -1}
    loconav: {size: [64, 64], repeat: 2, camera: -1}
    gym: {obs_key: state}
    robopianist: {render_image: true}
  
  # Evaluation settings
  eval:
    eval_freq: 2048  # Evaluate every 2048 callback calls (matches rollout frequency)
    n_eval_episodes: 5  # Reduced episodes since we're evaluating much more frequently
    eval_envs: 4  # Number of parallel environments for evaluation
    video_log_interval: 1  # Log videos every evaluation call
    num_eval_configs: 4
  
  # Training settings
  log_interval: 1  # Log every rollout

# ====================
# Named Configs
# ====================

# Tiger Door Key
gymnasium_tigerdoorkey: &tigerdoorkey_base
  task: gymnasium_TigerDoorKey-v0
  total_timesteps: 400000
  keys: {mlp_keys: '\b(neighbors|door|doors_unlocked|position|has_key)\b', cnn_keys: '^$'}
  # Reduced learning rate for stability in simple grid environment
  ppo:
    learning_rate: 1e-4      # Reduced from 3e-4 for more stable learning -- this grid environment tends to be unstable
  num_eval_configs: 4
  eval_keys:
    env1:
      mlp_keys: '\b(neighbors|door|doors_unlocked|position|has_key)\b'
      cnn_keys: '^$'

    env2: # must press button to reveal tiger/treasure up-down relative position. starts with key
      mlp_keys: '\b(neighbors_unprivileged_nokey|door_unprivileged|doors_unlocked|position|has_key)\b'
      cnn_keys: '^$'

    env3:  # must get key to reveal unlocked doors. starts with button
      mlp_keys: '\b(neighbors_unprivileged_nobutton|door|doors_unlocked_unprivileged|position|has_key)\b'
      cnn_keys: '^$'

    env4:  # must press button and get key to reveal unlocked doors and tiger/treasure relative position. starts with nothing
      mlp_keys: '\b(neighbors_unprivileged|door_unprivileged|doors_unlocked_unprivileged|position|has_key)\b'
      cnn_keys: '^$'

  exp_name: "tigerdoorkey_ppo"

gymnasium_tigerdoorkeylarge:
  << : *tigerdoorkey_base
  task: "gymnasium_tigerdoorkeylarge"
  total_timesteps: 500000
  exp_name: "tigerdoorkeylarge_ppo"

gymnasium_maze: &maze_base
  task: gymnasium_Maze7x7-v0
  total_timesteps: 500000
  keys: {mlp_keys: '\b(goal_position|position|neighbors_3x3|neighbors_5x5)\b', cnn_keys: '^$'}  # omit the distance key
  # Reduced learning rate for stability in simple grid environment
  ppo:
    learning_rate: 1e-4      # Reduced from 3e-4 for more stable learning
  num_eval_configs: 6
  eval_keys:  # Note that neighbors_5x5 only includes neighbors not in the 3x3 neighbors (they are disjoint)
    env1:  # Goal position, neighbors 5x5
      mlp_keys: '\b(goal_position|position|neighbors_3x3|neighbors_5x5)\b'
      cnn_keys: '^$'
    
    env2:  # Goal position, neighbors_3x3
      mlp_keys: '\b(goal_position|position|neighbors_3x3)\b'
      cnn_keys: '^$'
    
    env3:  # No goal position, neighbors_3x3
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3)\b'
      cnn_keys: '^$'

    env4:  # No goal position, neighbors_5x5
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3|neighbors_5x5)\b'
      cnn_keys: '^$'
    
    env5: # No goal position, neighbors_3x3 unprivileged
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3_unprivileged)\b'
      cnn_keys: '^$'
    
    env6: # No goal position, neighbors_5x5 unprivileged
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3_unprivileged|neighbors_5x5_unprivileged)\b'
      cnn_keys: '^$'

  exp_name: "maze_ppo"

gymnasium_maze11:
  << : *maze_base
  task: gymnasium_Maze11x11-v0
  total_timesteps: 1500000
  exp_name: "maze11_ppo"

# Blind Pick environment
gymnasium_blindpick: &blindpick_base
  task: gymnasium_FOFixedGripper2DBlind7cmPick-v0
  total_timesteps: 5000000
  num_envs: 32
  log_keys_video: [camera_front]
  # mlp keys: robot_state, touch, obj_state
  # cnn keys: camera_front, camera_side, gripper_camera_rgb
  keys: {mlp_keys: '.*', cnn_keys: '.*'}
  num_eval_configs: 7
  eval_keys:
    env1: # full privileged observations -- reach directly for object
      mlp_keys: '.*'
      cnn_keys: '.*'
    env2:  # NO TOUCH -- reach directly without touch
      mlp_keys: '\b(robot_state|obj_state)\b'
      cnn_keys: '.*'
    env3:  # NO OBJ STATE -- reach directly using image and not obj state
      mlp_keys: '\b(robot_state|touch)\b'
      cnn_keys: '.*'
    env4: # NO OBJ STATE, only a wrist camera -- searching behavior
      mlp_keys: '\b(robot_state|touch)\b'
      cnn_keys: 'gripper_camera_rgb'
    env5:  # full state, only wrist camera -- searching but obj_state gives it away
      mlp_keys: '.*'
      cnn_keys: 'gripper_camera_rgb'
    env6:  # full state, only front camera -- searching but image, obj_state gives it away
      mlp_keys: '.*'
      cnn_keys: 'camera_front'
    env7:  # full state, only side camera -- searching but image, obj_state gives it away
      mlp_keys: '.*'
      cnn_keys: 'camera_side'

  exp_name: "blindpick_ppo"

# Blind Pick with different sensor configurations
blindpick_oracle_state:
  << : *blindpick_base
  keys: {mlp_keys: r'\b(robot_state|obj_state)\b', cnn_keys: '^$'}
  eval_keys:
    env1: # oracle state (robot_state + obj_state)
      mlp_keys: r'\b(robot_state|obj_state)\b'
      cnn_keys: '^$'
  exp_name: "blindpick_oracle_state_ppo"

blindpick_vision_only:
  << : *blindpick_base
  keys: {mlp_keys: '^$', cnn_keys: '.*'}
  eval_keys:
    env1: # vision only
      mlp_keys: '^$'
      cnn_keys: '.*'
  exp_name: "blindpick_vision_only_ppo"

blindpick_touch_vision:
  << : *blindpick_base
  keys: {mlp_keys: 'touch', cnn_keys: '.*'}
  eval_keys:
    env1: # touch + vision
      mlp_keys: 'touch'
      cnn_keys: '.*'
  exp_name: "blindpick_touch_vision_ppo"

blindpick_robot_state_vision:
  << : *blindpick_base
  keys: {mlp_keys: 'robot_state', cnn_keys: '.*'}
  eval_keys:
    env1: # robot state + vision
      mlp_keys: 'robot_state'
      cnn_keys: '.*'
  exp_name: "blindpick_robot_state_vision_ppo" 


# Aerial Gym Environment
gymnasium_aerialnavigation: &aerialnavigation_base
  task: isaacgym_navigation_task_custom-v0
  total_timesteps: 5000000 # 5 mil initially
  keys: {mlp_keys: '.*', cnn_keys: '.*'}
  num_envs: 128
  num_eval_configs: 4
  eval_keys:
  # for temporary testing, set each eval key to use a different "image" but keep all the state info
    env1:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env2:
      mlp_keys: '.*'
      cnn_keys: 'depth_image'

    env3: # must press button to reveal tiger/treasure up-down relative position. starts with key
      mlp_keys: '.*'
      cnn_keys: 'rgb_image'

    env4:  # must get key to reveal unlocked doors. starts with button
      mlp_keys: '.*'
      cnn_keys: 'segmentation_image'

  exp_name: "aerialnavigation_ppo"