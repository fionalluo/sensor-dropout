defaults:
  exp_name: simple_imitation
  seed: 0
  torch_deterministic: true
  cuda: false
  track: true
  wandb_project: "ppo-distill-baseline"
  wandb_entity: null

  task: gymnasium_TigerDoorKey-v0
  total_timesteps: 500000
  num_envs: 8

  # Multi-teacher distillation specific parameters
  distillation:
    learning_rate: 3e-4              # Learning rate for PyTorch optimizer
    batch_size: 64                   # Batch size for distillation training
    steps_per_rollout: 128           # Steps per data collection rollout
    num_minibatches: 4               # Number of minibatches per update
    update_epochs: 4                 # Number of training epochs per iteration
    temperature: 1.0                 # Temperature for distillation
    distillation_loss_weight: 1.0    # Weight for distillation loss
    episodes_per_iteration: 5        # Episodes to collect per training iteration
    gradient_clip_norm: null         # Gradient clipping norm (null = no clipping)
    l2_regularization: 0.0           # L2 regularization coefficient
  
  # Evaluation settings
  eval:
    eval_freq: 2048  # Evaluate every 2048 steps (matches rollout frequency)
    n_eval_episodes: 5  # Reduced episodes since we're evaluating much more frequently

  # Student observation keys (what the student policy can see)
  keys: {mlp_keys: '.*', cnn_keys: '.*'}
  
  # Teacher configurations (what each teacher was trained with)
  num_eval_configs: 4
  eval_keys:
    env1:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env2:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env3:
      mlp_keys: '.*'
      cnn_keys: '.*'
    env4:
      mlp_keys: '.*'
      cnn_keys: '.*'

  save_model: false

  # Environment settings
  env:
    atari: {size: [64, 64], repeat: 4, sticky: True, gray: False, actions: all, lives: unused, noops: 0, resize: opencv}
    dmlab: {size: [64, 64], repeat: 4, episodic: True}
    minecraft: {size: [64, 64], break_speed: 100.0}
    dmc: {size: [64, 64], repeat: 2, camera: -1}
    loconav: {size: [64, 64], repeat: 2, camera: -1}
    gym: {obs_key: state}
    robopianist: {render_image: true}

# ====================
# Named Configs
# ====================

# Tiger Door Key
gymnasium_tigerdoorkey: &tigerdoorkey_base
  task: gymnasium_TigerDoorKey-v0
  total_timesteps: 400000  # Reduced for testing
  # Student sees all privileged observations
  keys: {mlp_keys: '\b(neighbors|door|doors_unlocked|position|has_key)\b', cnn_keys: '^$'}
  # Reduced learning rate for stability in simple grid environment
  distillation:
    learning_rate: 1e-4    # Increased since we removed L2 reg and use cross entropy
    gradient_clip_norm: 0.5  # Add gradient clipping for stability
    l2_regularization: 0.0  # Remove L2 regularization - we want student to match teacher exactly
  eval:
    eval_freq: 2048        # Evaluate every 2048 steps (matches rollout frequency)
    n_eval_episodes: 20     # Increased episodes for more stable evaluation metrics
  num_eval_configs: 4
  eval_keys:
    env1:  # Full privileged teacher
      mlp_keys: '\b(neighbors|door|doors_unlocked|position|has_key)\b'
      cnn_keys: '^$'
    env2: # Button-limited teacher (must press button to reveal tiger/treasure relative position)
      mlp_keys: '\b(neighbors_unprivileged_nokey|door_unprivileged|doors_unlocked|position|has_key)\b'
      cnn_keys: '^$'

    env3:  # Key-limited teacher (must get key to reveal unlocked doors)
      mlp_keys: '\b(neighbors_unprivileged_nobutton|door|doors_unlocked_unprivileged|position|has_key)\b'
      cnn_keys: '^$'

    env4:  # Most limited teacher (must press button and get key)
      mlp_keys: '\b(neighbors_unprivileged|door_unprivileged|doors_unlocked_unprivileged|position|has_key)\b'
      cnn_keys: '^$'

  exp_name: "tigerdoorkey_simple_imitation"

gymnasium_tigerdoorkeylarge:
  << : *tigerdoorkey_base
  task: "gymnasium_tigerdoorkeylarge"
  total_timesteps: 500000
  exp_name: "tigerdoorkeylarge_multi_teacher_distill"

gymnasium_maze: &maze_base
  task: gymnasium_Maze7x7-v0
  total_timesteps: 400000
  # Student sees all observations
  keys: {mlp_keys: '\b(goal_position|position|neighbors_3x3|neighbors_5x5)\b', cnn_keys: '^$'}
  num_eval_configs: 6
  eval_keys:
    env1:  # Full privileged teacher (goal position + all neighbors)
      mlp_keys: '\b(goal_position|position|neighbors_3x3|neighbors_5x5)\b'
      cnn_keys: '^$'
    
    env2:  # Goal + limited neighbors teacher
      mlp_keys: '\b(goal_position|position|neighbors_3x3)\b'
      cnn_keys: '^$'
    
    env3:  # No goal, limited neighbors teacher
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3)\b'
      cnn_keys: '^$'

    env4:  # No goal, all neighbors teacher
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3|neighbors_5x5)\b'
      cnn_keys: '^$'
    
    env5: # No goal, very limited teacher
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3_unprivileged)\b'
      cnn_keys: '^$'
    
    env6: # Most limited teacher
      mlp_keys: '\b(goal_position_unprivileged|position|neighbors_3x3_unprivileged|neighbors_5x5_unprivileged)\b'
      cnn_keys: '^$'

  exp_name: "maze_multi_teacher_distill"

gymnasium_maze11:
  << : *maze_base
  task: gymnasium_Maze11x11-v0
  total_timesteps: 1500000
  exp_name: "maze11_multi_teacher_distill"

# Blind Pick environment
gymnasium_blindpick: &blindpick_base
  task: gymnasium_FOFixedGripper2DBlind7cmPick-v0
  total_timesteps: 5000000
  num_envs: 32
  # Student has access to all modalities
  keys: {mlp_keys: '.*', cnn_keys: '.*'}
  num_eval_configs: 7
  eval_keys:
    env1: # Full multimodal teacher
      mlp_keys: '.*'
      cnn_keys: '.*'
    env2:  # Robot state only teacher (no touch, all cameras)
      mlp_keys: 'robot_state'
      cnn_keys: '.*'
    env3:  # Touch only teacher (no robot state, all cameras)
      mlp_keys: 'touch'
      cnn_keys: '.*'
    env4: # Vision only teacher (no proprioception)
      mlp_keys: '^$'
      cnn_keys: '.*'
    env5:  # Limited vision teacher (only wrist camera)
      mlp_keys: '.*'
      cnn_keys: 'gripper_camera_rgb'
    env6:  # Front camera only teacher
      mlp_keys: '.*'
      cnn_keys: 'camera_front'
    env7:  # Side camera only teacher
      mlp_keys: '.*'
      cnn_keys: 'camera_side'

  exp_name: "blindpick_multi_teacher_distill"

# Specialized configurations for different sensor modalities
blindpick_oracle_state:
  << : *blindpick_base
  keys: {mlp_keys: r'\b(robot_state|obj_state)\b', cnn_keys: '^$'}
  eval_keys:
    env1: # Oracle state teacher (full state information)
      mlp_keys: r'\b(robot_state|obj_state)\b'
      cnn_keys: '^$'
  exp_name: "blindpick_oracle_state_multi_teacher_distill"

blindpick_vision_only:
  << : *blindpick_base
  keys: {mlp_keys: '^$', cnn_keys: '.*'}
  eval_keys:
    env1: # Vision only teacher
      mlp_keys: '^$'
      cnn_keys: '.*'
  exp_name: "blindpick_vision_only_multi_teacher_distill"

blindpick_touch_vision:
  << : *blindpick_base
  keys: {mlp_keys: 'touch', cnn_keys: '.*'}
  eval_keys:
    env1: # Touch + vision teacher
      mlp_keys: 'touch'
      cnn_keys: '.*'
  exp_name: "blindpick_touch_vision_multi_teacher_distill" 